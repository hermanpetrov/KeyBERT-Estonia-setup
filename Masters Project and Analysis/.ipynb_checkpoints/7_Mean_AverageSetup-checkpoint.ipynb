{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c33410c5-4545-4625-be6c-e4e1d5a2483d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files processed: 5907\n",
      "Files not processed across all folders:\n",
      "t103140.csv\n",
      "t103140.csv\n",
      "t103140.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Base and output directories\n",
    "base_path = \"./models/unified_data_10/raw_text_lemma_data_LCF\"  # iterate through raw_text_data;raw_text_data_lcf;raw_text_lemma_data;raw_text_lemma_data_LCF;\n",
    "philologist_path = \"./filol_scores/keywords_lemma/philologist_M2\"  # keywords/philologist_M1;keywords/philologist_M2;keywords_lemma/philologist_M1;keywords_lemma/philologist_M2\n",
    "output_dir = \"./models/diversity_accuracy/raw_text_lemma_data_LCF\"  # iterate through raw_text_data;raw_text_data_lcf;raw_text_lemma_data;raw_text_lemma_data_LCF;\n",
    "\n",
    "ngram_dirs = [\"ngram_1_1\", \"ngram_2_2\", \"ngram_3_3\"]\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "processed_files_count = 0\n",
    "unprocessed_files = []\n",
    "\n",
    "\n",
    "def process_ngram_directory(ngram_dir):\n",
    "    global processed_files_count, unprocessed_files\n",
    "    diversity_paths = [f\"{base_path}/{ngram_dir}/diversity_{i}\" for i in range(11)]\n",
    "\n",
    "    for philologist_file in os.listdir(philologist_path):\n",
    "        if philologist_file.endswith(\".csv\"):\n",
    "            philologist_file_path = os.path.join(philologist_path, philologist_file)\n",
    "            df_philologist = pd.read_csv(philologist_file_path, delimiter=\";\")\n",
    "            philologist_keywords = (\n",
    "                df_philologist[\"keyword\"].dropna().str.lower().unique()\n",
    "            )\n",
    "            expected_amount = len(philologist_keywords)\n",
    "            model_names = [\n",
    "                \"EstBERT\",\n",
    "                \"est-roberta\",\n",
    "                \"LaBSE\",\n",
    "                \"bertMulti\",\n",
    "                \"distilbertMulti\",\n",
    "                \"MiniLM_multi\",\n",
    "                \"MiniLM-L12_multi\",\n",
    "                \"multi_e5\",\n",
    "                \"xml_roberta\",\n",
    "            ]\n",
    "            results = {model: [0] * 11 for model in model_names}\n",
    "            found_words = [{model: set() for model in model_names} for _ in range(11)]\n",
    "\n",
    "            matching_files_exist = False\n",
    "            for idx, path in enumerate(diversity_paths):\n",
    "                diversity_file_path = os.path.join(path, philologist_file)\n",
    "                if os.path.exists(diversity_file_path):\n",
    "                    matching_files_exist = True\n",
    "                    break\n",
    "\n",
    "            if matching_files_exist:\n",
    "                for idx, path in enumerate(diversity_paths):\n",
    "                    diversity_file_path = os.path.join(path, philologist_file)\n",
    "                    if os.path.exists(diversity_file_path):\n",
    "                        df_diversity = pd.read_csv(\n",
    "                            diversity_file_path, delimiter=\";\", names=model_names\n",
    "                        )\n",
    "                        for model in model_names:\n",
    "                            entries = (\n",
    "                                df_diversity[model].dropna().str.lower().str.split()\n",
    "                            )\n",
    "                            model_specific_words = set()\n",
    "                            for entry in entries:\n",
    "                                matched_words = set(entry) & set(philologist_keywords)\n",
    "                                model_specific_words.update(matched_words)\n",
    "                            found_words[idx][model] = model_specific_words\n",
    "                            results[model][idx] = len(model_specific_words)\n",
    "                        processed_files_count += 1\n",
    "\n",
    "                output_df = pd.DataFrame(\n",
    "                    results, index=[f\"diversity_{i}\" for i in range(11)]\n",
    "                )\n",
    "                output_df.reset_index(inplace=True)\n",
    "                output_df.rename(columns={\"index\": \"diversity\"}, inplace=True)\n",
    "                output_df[\"expected_amount\"] = expected_amount\n",
    "                output_df[\"words\"] = [\n",
    "                    \"; \".join(set().union(*(d.values()))) for d in found_words\n",
    "                ]\n",
    "\n",
    "                ngram_output_dir = os.path.join(output_dir, ngram_dir)\n",
    "                os.makedirs(ngram_output_dir, exist_ok=True)\n",
    "                output_path = os.path.join(ngram_output_dir, philologist_file)\n",
    "                output_df.to_csv(output_path, index=False)\n",
    "            else:\n",
    "                unprocessed_files.append(philologist_file)\n",
    "\n",
    "\n",
    "for ngram_dir in ngram_dirs:\n",
    "    process_ngram_directory(ngram_dir)\n",
    "\n",
    "print(f\"Total number of files processed: {processed_files_count}\")\n",
    "if unprocessed_files:\n",
    "    print(\"Files not processed across all folders:\")\n",
    "    for file in unprocessed_files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"All files were successfully processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede260d6-735c-4201-8b1b-d64183a30e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def process_all(sizes, models, data_types):\n",
    "    for size in sizes:\n",
    "        for model in models:\n",
    "            for data_type in data_types:\n",
    "\n",
    "                base_path = f\"./models/unified_data_{size}/{data_type}\"\n",
    "                if \"lemma\" in data_type:\n",
    "                    philologist_path = (\n",
    "                        f\"./filol_scores/keywords_lemma/philologist_{model}\"\n",
    "                    )\n",
    "                else:\n",
    "                    philologist_path = f\"./filol_scores/keywords/philologist_{model}\"\n",
    "                output_dir = f\"./models/diversity_accuracy_{size}_{model}/{data_type}\"\n",
    "\n",
    "                ngram_dirs = [\"ngram_1_1\", \"ngram_2_2\", \"ngram_3_3\"]\n",
    "\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "                def process_ngram_directory(ngram_dir):\n",
    "                    diversity_paths = [\n",
    "                        f\"{base_path}/{ngram_dir}/diversity_{i}\" for i in range(11)\n",
    "                    ]\n",
    "                    for philologist_file in os.listdir(philologist_path):\n",
    "                        if philologist_file.endswith(\".csv\"):\n",
    "                            philologist_file_path = os.path.join(\n",
    "                                philologist_path, philologist_file\n",
    "                            )\n",
    "                            df_philologist = pd.read_csv(\n",
    "                                philologist_file_path, delimiter=\";\"\n",
    "                            )\n",
    "                            philologist_keywords = (\n",
    "                                df_philologist[\"keyword\"].dropna().str.lower().unique()\n",
    "                            )\n",
    "                            model_names = [\n",
    "                                \"EstBERT\",\n",
    "                                \"est-roberta\",\n",
    "                                \"LaBSE\",\n",
    "                                \"bertMulti\",\n",
    "                                \"distilbertMulti\",\n",
    "                                \"MiniLM_multi\",\n",
    "                                \"MiniLM-L12_multi\",\n",
    "                                \"multi_e5\",\n",
    "                                \"xml_roberta\",\n",
    "                            ]\n",
    "                            results = {\n",
    "                                model_name: [0] * 11 for model_name in model_names\n",
    "                            }\n",
    "                            found_words = [\n",
    "                                {model_name: set() for model_name in model_names}\n",
    "                                for _ in range(11)\n",
    "                            ]\n",
    "\n",
    "                            for idx, path in enumerate(diversity_paths):\n",
    "                                diversity_file_path = os.path.join(\n",
    "                                    path, philologist_file\n",
    "                                )\n",
    "                                if os.path.exists(diversity_file_path):\n",
    "                                    df_diversity = pd.read_csv(\n",
    "                                        diversity_file_path,\n",
    "                                        delimiter=\";\",\n",
    "                                        names=model_names,\n",
    "                                    )\n",
    "                                    for model_name in model_names:\n",
    "                                        if model_name in df_diversity.columns:\n",
    "                                            entries = (\n",
    "                                                df_diversity[model_name]\n",
    "                                                .dropna()\n",
    "                                                .astype(str)\n",
    "                                                .str.lower()\n",
    "                                                .str.split()\n",
    "                                            )\n",
    "                                            model_specific_words = set()\n",
    "                                            for entry in entries:\n",
    "                                                matched_words = set(entry) & set(\n",
    "                                                    philologist_keywords\n",
    "                                                )\n",
    "                                                model_specific_words.update(matched_words)\n",
    "                                            found_words[idx][\n",
    "                                                model_name\n",
    "                                            ] = model_specific_words\n",
    "                                            results[model_name][idx] = len(\n",
    "                                                model_specific_words\n",
    "                                            )\n",
    "\n",
    "                            output_df = pd.DataFrame(\n",
    "                                results, index=[f\"diversity_{i}\" for i in range(11)]\n",
    "                            )\n",
    "                            output_df[\"expected_amount\"] = len(philologist_keywords)\n",
    "                            output_df[\"words\"] = [\n",
    "                                \"; \".join(set().union(*(d.values())))\n",
    "                                for d in found_words\n",
    "                            ]\n",
    "                            ngram_output_dir = os.path.join(output_dir, ngram_dir)\n",
    "                            os.makedirs(ngram_output_dir, exist_ok=True)\n",
    "                            output_df.to_csv(\n",
    "                                os.path.join(ngram_output_dir, philologist_file),\n",
    "                                index=False,\n",
    "                            )\n",
    "\n",
    "                for ngram_dir in ngram_dirs:\n",
    "                    process_ngram_directory(ngram_dir)\n",
    "\n",
    "\n",
    "sizes = [10, 50, 200]\n",
    "models = [\"M1\", \"M2\"]\n",
    "data_types = [\n",
    "    \"raw_text_data\",\n",
    "    \"raw_text_data_LCF\",\n",
    "    \"raw_text_lemma_data\",\n",
    "    \"raw_text_lemma_data_LCF\",\n",
    "]\n",
    "\n",
    "process_all(sizes, models, data_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182d92a-f1c9-4ad1-9d32-e1ccc816badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def process_data(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    model_columns = [\n",
    "        \"EstBERT\",\n",
    "        \"est-roberta\",\n",
    "        \"LaBSE\",\n",
    "        \"bertMulti\",\n",
    "        \"distilbertMulti\",\n",
    "        \"MiniLM_multi\",\n",
    "        \"MiniLM-L12_multi\",\n",
    "        \"multi_e5\",\n",
    "        \"xml_roberta\",\n",
    "    ]\n",
    "    data[\"diversity\"] = pd.Series(range(data.shape[0])) * (10 / (data.shape[0] - 1))\n",
    "    for column in model_columns:\n",
    "        if column in data.columns:\n",
    "            data[column] = data[column] / data[\"expected_amount\"]\n",
    "    return data\n",
    "\n",
    "\n",
    "def aggregate_and_rank(files, model_columns):\n",
    "    processed_files = [process_data(file) for file in files]\n",
    "    if not processed_files:\n",
    "        return pd.DataFrame()\n",
    "    aggregated_data = pd.concat(processed_files, ignore_index=True)\n",
    "    if \"diversity\" not in aggregated_data.columns:\n",
    "        return pd.DataFrame()\n",
    "    mean_scores = aggregated_data.groupby(\"diversity\")[model_columns].mean()\n",
    "    return mean_scores\n",
    "\n",
    "\n",
    "def get_best_combinations(mean_scores):\n",
    "    if mean_scores.empty:\n",
    "        return pd.DataFrame(columns=[\"Diversity\", \"Model\", \"Score\"])\n",
    "    \n",
    "    best_combinations = []\n",
    "\n",
    "    for diversity, row in mean_scores.iterrows():\n",
    "        highest_model = row.idxmax()\n",
    "        highest_score = row.max()\n",
    "        best_combinations.append([f\"diversity_{int(diversity)}\", highest_model, highest_score])\n",
    "    \n",
    "    best_combinations_df = pd.DataFrame(best_combinations, columns=[\"Diversity\", \"Model\", \"Score\"])\n",
    "    best_combinations_df = best_combinations_df.sort_values(by=\"Score\", ascending=False)\n",
    "    \n",
    "    return best_combinations_df\n",
    "\n",
    "\n",
    "diversity_levels = [\"10\", \"50\", \"200\"]\n",
    "model_types = [\"M1\", \"M2\"]\n",
    "subfolders = [\"ngram_1_1\", \"ngram_2_2\", \"ngram_3_3\"]\n",
    "model_columns = [\n",
    "    \"EstBERT\",\n",
    "    \"est-roberta\",\n",
    "    \"LaBSE\",\n",
    "    \"bertMulti\",\n",
    "    \"distilbertMulti\",\n",
    "    \"MiniLM_multi\",\n",
    "    \"MiniLM-L12_multi\",\n",
    "    \"multi_e5\",\n",
    "    \"xml_roberta\",\n",
    "]\n",
    "common_analytical_base = \"analytical_data\"\n",
    "\n",
    "if not os.path.exists(common_analytical_base):\n",
    "    os.makedirs(common_analytical_base)\n",
    "\n",
    "for diversity in diversity_levels:\n",
    "    for model_type in model_types:\n",
    "        input_base = f\"models/diversity_accuracy_{diversity}_{model_type}\"\n",
    "\n",
    "        for data_type in [\n",
    "            \"raw_text_lemma_data_LCF\",\n",
    "            \"raw_text_lemma_data\",\n",
    "            \"raw_text_data\",\n",
    "            \"raw_text_data_LCF\",\n",
    "        ]:\n",
    "            input_directory_path = os.path.join(input_base, data_type)\n",
    "            output_directory_path = os.path.join(\n",
    "                common_analytical_base,\n",
    "                f\"analytical_data_{diversity}_{model_type}\",\n",
    "                data_type,\n",
    "            )\n",
    "\n",
    "            if not os.path.exists(output_directory_path):\n",
    "                os.makedirs(output_directory_path)\n",
    "\n",
    "            for subfolder in subfolders:\n",
    "                print(\n",
    "                    f\"--- Processing data for {subfolder} in {input_directory_path} ---\"\n",
    "                )\n",
    "                directory_path = os.path.join(input_directory_path, subfolder)\n",
    "                files = [\n",
    "                    os.path.join(directory_path, file)\n",
    "                    for file in os.listdir(directory_path)\n",
    "                    if file.endswith(\".csv\")\n",
    "                ]\n",
    "                mean_scores = aggregate_and_rank(files, model_columns)\n",
    "                best_combinations = get_best_combinations(mean_scores)\n",
    "\n",
    "                output_csv_file = os.path.join(\n",
    "                    output_directory_path,\n",
    "                    f\"{subfolder}_best_combinations.csv\",\n",
    "                )\n",
    "                best_combinations.to_csv(output_csv_file, index=False)\n",
    "\n",
    "                print(f\"Results written to {output_csv_file}\")\n",
    "                print(\"\\n\" + \"=\" * 50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebec13d1-6ff7-4fa6-8aea-e45d68d21d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def process_data(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    model_columns = [\n",
    "        \"EstBERT\",\n",
    "        \"est-roberta\",\n",
    "        \"LaBSE\",\n",
    "        \"bertMulti\",\n",
    "        \"distilbertMulti\",\n",
    "        \"MiniLM_multi\",\n",
    "        \"MiniLM-L12_multi\",\n",
    "        \"multi_e5\",\n",
    "        \"xml_roberta\",\n",
    "    ]\n",
    "    data[\"diversity\"] = pd.Series(range(data.shape[0])) * (10 / (data.shape[0] - 1))\n",
    "    for column in model_columns:\n",
    "        if column in data.columns:\n",
    "            data[column] = data[column] / data[\"expected_amount\"]\n",
    "    return data\n",
    "\n",
    "\n",
    "def aggregate_and_rank(files, model_columns):\n",
    "    processed_files = [process_data(file) for file in files]\n",
    "    aggregated_data = pd.concat(processed_files, ignore_index=True)\n",
    "    mean_scores = aggregated_data.groupby(\"diversity\")[model_columns].mean()\n",
    "    return mean_scores\n",
    "\n",
    "\n",
    "def get_top_combinations(mean_scores, model_columns, top_n=10):\n",
    "    mean_scores_flat = mean_scores.stack().reset_index()\n",
    "    mean_scores_flat.columns = [\"Diversity\", \"Model\", \"Mean Score\"]\n",
    "    top_combinations = mean_scores_flat.sort_values(\n",
    "        by=\"Mean Score\", ascending=False\n",
    "    ).head(top_n)\n",
    "    return top_combinations\n",
    "\n",
    "\n",
    "diversity_levels = [\"10\", \"50\", \"200\"]\n",
    "model_types = [\"M1\", \"M2\"]\n",
    "subfolders = [\"ngram_1_1\", \"ngram_2_2\", \"ngram_3_3\"]\n",
    "model_columns = [\n",
    "    \"EstBERT\",\n",
    "    \"est-roberta\",\n",
    "    \"LaBSE\",\n",
    "    \"bertMulti\",\n",
    "    \"distilbertMulti\",\n",
    "    \"MiniLM_multi\",\n",
    "    \"MiniLM-L12_multi\",\n",
    "    \"multi_e5\",\n",
    "    \"xml_roberta\",\n",
    "]\n",
    "common_analytical_base = \"analytical_data\"\n",
    "\n",
    "if not os.path.exists(common_analytical_base):\n",
    "    os.makedirs(common_analytical_base)\n",
    "\n",
    "for diversity in diversity_levels:\n",
    "    for model_type in model_types:\n",
    "        input_base = f\"models/diversity_accuracy_{diversity}_{model_type}\"\n",
    "        output_base = os.path.join(\n",
    "            common_analytical_base, f\"analytical_data_{diversity}_{model_type}\"\n",
    "        )\n",
    "\n",
    "        if not os.path.exists(output_base):\n",
    "            os.makedirs(output_base)\n",
    "\n",
    "        for data_type in [\n",
    "            \"raw_text_lemma_data_LCF\",\n",
    "            \"raw_text_lemma_data\",\n",
    "            \"raw_text_data\",\n",
    "            \"raw_text_data_LCF\",\n",
    "        ]:\n",
    "            input_directory_path = os.path.join(input_base, data_type)\n",
    "            output_directory_path = os.path.join(output_base, data_type)\n",
    "\n",
    "            if not os.path.exists(output_directory_path):\n",
    "                os.makedirs(output_directory_path)\n",
    "\n",
    "            all_files = []\n",
    "            for subfolder in subfolders:\n",
    "                directory_path = os.path.join(input_directory_path, subfolder)\n",
    "                all_files.extend(\n",
    "                    [\n",
    "                        os.path.join(directory_path, file)\n",
    "                        for file in os.listdir(directory_path)\n",
    "                        if file.endswith(\".csv\")\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            mean_scores = aggregate_and_rank(all_files, model_columns)\n",
    "            top_combinations = get_top_combinations(mean_scores, model_columns)\n",
    "\n",
    "            output_csv_file = os.path.join(\n",
    "                output_directory_path, \"across_all_ngrams_top_10_combinations.csv\"\n",
    "            )\n",
    "            top_combinations.to_csv(output_csv_file, index=False)\n",
    "\n",
    "            print(f\"Results written to {output_csv_file}\")\n",
    "            print(\"\\n\" + \"=\" * 50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f8a6050-9dc2-41f9-b0fe-83c95e98fc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to analytical_data/results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def load_keywords(file_path, limit=None):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if \";\" in df.iloc[0, 0]:\n",
    "            keywords = df.iloc[:, 0].str.split(\";\").str[0].str.lower().unique()\n",
    "        else:\n",
    "            keywords = df.iloc[:, 0].str.lower().unique()\n",
    "        if limit:\n",
    "            keywords = keywords[:limit]\n",
    "        return set(keywords)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return set()\n",
    "\n",
    "\n",
    "def compare_keywords(base_keywords, comparison_files, limit):\n",
    "    results = {}\n",
    "    for file_path in comparison_files:\n",
    "        comp_keywords = load_keywords(file_path, limit=limit)\n",
    "        common_keywords = base_keywords.intersection(comp_keywords)\n",
    "        results[file_path] = len(common_keywords)\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    data_sets = [\n",
    "        {\n",
    "            \"label\": \"lemmas\",\n",
    "            \"base_dirs\": [\n",
    "                \"filol_scores/keywords_lemma/philologist_M1\",\n",
    "                \"filol_scores/keywords_lemma/philologist_M2\",\n",
    "            ],\n",
    "            \"comparison_dirs\": [\n",
    "                \"scores/SimpleMaths/lemmas\",\n",
    "                \"scores/TextRank/lemmas\",\n",
    "                \"scores/SimpleMaths/lemmas_LCF\",\n",
    "                \"scores/TextRank/lemmas_LCF\",\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"words\",\n",
    "            \"base_dirs\": [\n",
    "                \"filol_scores/keywords/philologist_M1\",\n",
    "                \"filol_scores/keywords/philologist_M2\",\n",
    "            ],\n",
    "            \"comparison_dirs\": [\n",
    "                \"scores/SimpleMaths/words\",\n",
    "                \"scores/TextRank/words\",\n",
    "                \"scores/SimpleMaths/words_LCF\",\n",
    "                \"scores/TextRank/words_LCF\",\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    keyword_limits = [200, 50, 10]\n",
    "    results = []\n",
    "\n",
    "    for data_set in data_sets:\n",
    "        for base_dir in data_set[\"base_dirs\"]:\n",
    "            M = base_dir.split(\"/\")[-1].split(\"_\")[1]\n",
    "            for comparison_dir in data_set[\"comparison_dirs\"]:\n",
    "                method = comparison_dir.split(\"/\")[-2]\n",
    "                wordtype = comparison_dir.split(\"/\")[-1]\n",
    "                for keyword_limit in keyword_limits:\n",
    "                    file_paths = [\n",
    "                        os.path.join(base_dir, file)\n",
    "                        for file in os.listdir(base_dir)\n",
    "                        if file.endswith(\".csv\")\n",
    "                    ]\n",
    "                    total_scores = []\n",
    "                    total_files = len(file_paths)\n",
    "\n",
    "                    for base_file in file_paths:\n",
    "                        base_keywords = load_keywords(base_file, limit=keyword_limit)\n",
    "                        comparison_file = os.path.join(\n",
    "                            comparison_dir, os.path.basename(base_file)\n",
    "                        )\n",
    "                        common_keywords = compare_keywords(\n",
    "                            base_keywords, [comparison_file], keyword_limit\n",
    "                        )\n",
    "                        if total_files > 0:\n",
    "                            score = (\n",
    "                                common_keywords[comparison_file] / len(base_keywords)\n",
    "                                if len(base_keywords) > 0\n",
    "                                else 0\n",
    "                            )\n",
    "                            total_scores.append(score)\n",
    "\n",
    "                    if total_scores:\n",
    "                        mean_score = sum(total_scores) / len(total_scores)\n",
    "                        results.append(\n",
    "                            {\n",
    "                                \"M\": M,\n",
    "                                \"Method\": method,\n",
    "                                \"word_limit\": keyword_limit,\n",
    "                                \"wordtype\": wordtype,\n",
    "                                \"score\": mean_score,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    save_path = \"analytical_data/results.csv\"\n",
    "    if not os.path.exists(\"analytical_data\"):\n",
    "        os.makedirs(\"analytical_data\")\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"Results saved to {save_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
